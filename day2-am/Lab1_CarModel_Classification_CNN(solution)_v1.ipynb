{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.linkpicture.com/q/nyplogo.jpg)\n",
    "Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n",
    "\n",
    "1. The notebook is composed of cells; cells can contain code which you can run, or they can hold text and/or images which are there for you to read.\n",
    "\n",
    "2. You can execute code cells by clicking the ```Run``` icon in the menu, or via the following keyboard shortcuts ```Shift-Enter``` (run and advance) or ```Ctrl-Enter``` (run and stay in the current cell).\n",
    "\n",
    "3. To interrupt cell execution, click the ```Stop``` button on the toolbar or navigate to the ```Kernel``` menu, and select ```Interrupt ```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFoLOed-Vm5R"
   },
   "source": [
    "# Lab 1 (solution): Car Model Classification with CNN\n",
    "In this Lab we will try to build a Vehicle Classifier to classify three different models of the car. We will collect 3 groups of images namely  Honda Civic, Toyota Altis and Volkswagen Passat as our dataset. Then use the dataset to train the Renet50 CNN(Convolution Neural Network). Upon completed training the neural network we will be able to classify an unknown image to give a predicted the model of the car.  \n",
    "\n",
    "\n",
    "We will build the car model classifier based on the following steps\n",
    "\n",
    "1.   Install the python modules   \n",
    "2.   Import the libraries needed for the program\n",
    "3.  Prepare the data\n",
    "4.   Prepare the CNN model\n",
    "5.  Train the model with the training set and evaluate its performance\n",
    "6.   Use the trained model to classify input data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gr9UQHf5JwE3"
   },
   "source": [
    "# 1. Install Python Modules\n",
    "The libraries needed for the lab are preinstalled in the VM.\n",
    "\n",
    "The following are examples of how the modules are installed.\n",
    "\n",
    "Use the pip(python install program) to install the following modules\n",
    "* !pip install tensorflow==1.13.1\n",
    "* !pip install keras==2.1.6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj1dHMgCLr9a"
   },
   "source": [
    "# 2. Import the libraries needed for the program\n",
    "We will begin by importing the libraries that we need, mainly Keras.  \n",
    "Keras is based on minimal structure that provides a clean and easy way to create deep learning models based on TensorFlow or Theano.\n",
    "Keras contains useful functions for image data preprocess and defining the convolution neural network.\n",
    "Matplotlib is used for data visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2369,
     "status": "ok",
     "timestamp": 1600739644086,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "LjhErGYmV2Qi",
    "outputId": "129e7331-85da-4362-9c7d-4fc502d1be67"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers, regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1600739647808,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "EAx4b2JXiWYm",
    "outputId": "e8e8bc65-31a7-46ae-836a-ff427ed175ae"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhr5JMTPMBlo"
   },
   "source": [
    "# 3. Prepare the data\n",
    "Training Data: Collection of sample of data used to train the neural network.\n",
    "\n",
    "Validation Data: Collection of sample of data used to provide an unbiased evaluation of neural netowork during the training.\n",
    "\n",
    "Test Data: Collection of sample data used to evaluate the trained neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJqGwgQNaDf"
   },
   "source": [
    "### 3.1 Collect data for training and validation\n",
    "\n",
    "\n",
    "```\n",
    "In the path ./dataset/Lab1dataset/data/\n",
    "create a train directory with following subdir\n",
    "train \n",
    "   |- Honda\n",
    "   |- Toyota\n",
    "   |- Volkswagen \n",
    "copy 60 different jpg images for each of the car model into the above subdir(Honda, Toyota, Volkawagen)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "In the path ./dataset/Lab1dataset/data/\n",
    "create a validation directory with following subdir\n",
    "validation \n",
    "   |- Honda\n",
    "   |- Toyota\n",
    "   |- Volkswagen \n",
    "copy 15 different jpg images for each of the car model into the above subdir(Honda, Toyota, Volkawagen)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "In the path ./dataset/Lab1dataset/\n",
    "creat a dir prediction_images\n",
    "./dataset/lab1dataset/\n",
    "    |- prediction_images\n",
    "Copy some test images inside this directory. This images are used to test the trained model.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1208,
     "status": "ok",
     "timestamp": 1600739785215,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "UqJN2hz7ZUy_"
   },
   "outputs": [],
   "source": [
    "# Define train data paths, validation data path and test data path \n",
    "data_dir_path='./dataset/Lab1dataset/data/'\n",
    "train_data_dir = data_dir_path+'train/'\n",
    "validation_data_dir = data_dir_path+'validation/'\n",
    "prediction_data_dir = './dataset/Lab1dataset/prediction_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Let explore the images we had collected in the train dataset.\n",
    "\n",
    "Try to display different images with the following code.\n",
    "\n",
    "What do you notice about the images? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(train_data_dir+\"Honda/100.jpg\")\n",
    "imgplot = plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDuVmIyrSoFe"
   },
   "source": [
    "### 3.2 Prepare Data for training and validation\n",
    "\n",
    "Data augmentation is a strategy that enables developer to significantly increase the diversity of data available for training models, without actually collecting new data. \n",
    "\n",
    "Data augmentation techniques such as resizing, rotation, and cropping are commonly used to train large neural networks.\n",
    "\n",
    "\n",
    "![image](https://www.linkpicture.com/q/Augmentation.png)\n",
    "\n",
    "\n",
    "Kera provides us a function to do data augmentation. We can configure the arguments in the function to achieve the required image augmentation. We will do some of the configuration in the exercise.\n",
    " \n",
    "Next we will construct the final train and validation dataset using the configured image augmentation, final image size(width and height) and batch size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "We will configure the image augmentation arguments for the train and validation data.\n",
    "\n",
    "Here are some for the arguments.\n",
    "\n",
    "rescale factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided. Most of the time we rescale based on the greyscale eg. 1./255\n",
    "\n",
    "shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees) eg. 0.2 degrees\n",
    "\n",
    "zoom_range: Float. zoom range for width and height. eg. 0.2\n",
    "\n",
    "horizontal_flip: Boolean. Randomly flip inputs horizontally.eg. True\n",
    "\n",
    "add the configuration value in the area #add code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1600739968263,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "DKKq1Nu0biPQ"
   },
   "outputs": [],
   "source": [
    "#Prepare Data for training and validation\n",
    "\n",
    "def PrepareData(img_width,img_height,batch_size ):\n",
    "\n",
    "    # This augments the data. This is usefull when working with a small sample size\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale= 1./255,\n",
    "        shear_range= 0.2,\n",
    "        zoom_range= 0.2,\n",
    "        horizontal_flip= True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    print(\"train generator\")\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"validation generator\")\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "    return train_generator,validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6KWkyz_PjU3"
   },
   "source": [
    "### 3.3 Get the total number of predicted classes/labels\n",
    "\n",
    "Labels are the final output of prediction. You can also consider the output classes to be the labels. When we speak of labeled data, they mean groups of samples that have been tagged to one or more labels.\n",
    "\n",
    "In our case, all the honda civic images are labeled as Honda. All the toyota altis images are labeled Toyota and all the volkswagen passat images are labeled Volkawagen.\n",
    "\n",
    "\n",
    "From the train subdir we can get the number of classes\n",
    "\n",
    "\n",
    "> The numbers of classes are categories of object we wanted to predict (3)\n",
    "\n",
    "> The numbers of subdir in the training dir will be the classes/labels name (Honda, Toyota, Volkswagen)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Where can be get the information for the number of classes and the Label names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4137,
     "status": "ok",
     "timestamp": 1600739818578,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "e_REo5X_bhxa",
    "outputId": "7834c36b-22e6-4164-c6d2-a2ccf99327f6"
   },
   "outputs": [],
   "source": [
    "# Gets the total no. of classes\n",
    "classes = ImageDataGenerator().flow_from_directory(train_data_dir).class_indices\n",
    "print(classes)\n",
    "print(len(classes))\n",
    "num_classes= len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QO0RcRNQSS0-"
   },
   "source": [
    "# 4. Prepare the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3-_hKmxN20M"
   },
   "source": [
    "### 4.1 CNN Convolution Netural Network\n",
    "\n",
    "![image](https://www.linkpicture.com/q/resnet50.png)\n",
    "\n",
    "> Use the Resnet50 CNN model\n",
    "\n",
    "> Each typical CNN layer comprise of Conv + Activation function + Maxpooling\n",
    "\n",
    "> Each CNN layer can be added into the Keras Sequential \n",
    "\n",
    "> Define the parameters for each of the CNN layer\n",
    "\n",
    "        *   Conv2D-> number of feature map, feature map size (width x height)\n",
    "        *   Activation function -> relu , sigmoid \n",
    "        *   MaxPooling-> kernel size (width x height)\n",
    "\n",
    ">Define the output layer\n",
    "\n",
    "        *   Flatten-> 2D to 1D\n",
    "        *   Dense layer->number of neutrons\n",
    "        *   Activation Function->softmax(probability of each the classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execrise\n",
    "We had resized all images in our dataset to be the same size as the input to the Resnet50 model.\n",
    "\n",
    "What is the output of the Resnet50 model? \n",
    "What is the learning rate for model?\n",
    "\n",
    "The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error. It is range from 0 to 1. The bigger the number the bigger the response step. The learning rate is one of the important perparameter when configuring your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1600740460029,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "KH0ec4qCf7FS"
   },
   "outputs": [],
   "source": [
    "def compileModel(img_width, img_height,learning_rate=1e-4):\n",
    "    print(\"compiling model\")\n",
    "\n",
    "    # Insureing that the images are in the correct format.\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "    img_color=3\n",
    "\n",
    "    conv_base = ResNet50(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(img_width, img_height, img_color))\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    #Add dense and classification layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # print(model.summary())\n",
    "    # print(conv_base.summary())\n",
    "    model.compile(loss='categorical_crossentropy',optimizer= optimizers.adam(lr=learning_rate),metrics=['accuracy'])\n",
    "    for layer in conv_base.layers:\n",
    "      layer.trainable = False\n",
    "    for layer in conv_base.layers[-4:]:\n",
    "      layer.trainable = True\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some checkpoint to save the best trained model during the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1523,
     "status": "ok",
     "timestamp": 1600740131384,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "zMUegDZ9gY62"
   },
   "outputs": [],
   "source": [
    "best_model = keras.callbacks.ModelCheckpoint(data_dir_path+'custom_w_supervision_try2_best' + '.h5', monitor='val_acc',save_best_only=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss',factor=0.25, patience=5,min_lr=0.000005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAFGrHhTTIWX"
   },
   "source": [
    "# 5. Train the model with the training set and evaluate it performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1V4dlZyHUVTM"
   },
   "source": [
    "### 5.1 Train and validate the model\n",
    "\n",
    "\n",
    " [![image](https://www.linkpicture.com/q/training.png)\n",
    "\n",
    "With the preprocessed training and validation dataset. We can input them into the our defined model for training.\n",
    "We will then set the parameters of the training.\n",
    "\n",
    "Set the number of epoch to  indicates the number of passes of the entire training dataset the model has to complete.\n",
    "\n",
    "When we have a huge data set it not possible to load the entire data to run one epoch of training. Setting Step per epoch allow huge data to divide into batches to complete entire training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1600740440814,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "Nf9oc01xgnos"
   },
   "outputs": [],
   "source": [
    "def trainModel(train_data, validation_data,model):\n",
    "\n",
    "    print(\"starting training.... \")\n",
    "    hist = model.fit_generator(\n",
    "        (train_data),\n",
    "        steps_per_epoch=nb_train_samples // batch_size, # The accumulated amount of steps\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_data,\n",
    "        nb_val_samples=nb_validation_samples,\n",
    "        callbacks=[best_model, reduce_lr]\n",
    "    )\n",
    "\n",
    "    plotVal_plotLoss(hist)\n",
    "    model.save_weights(data_dir_path+'custom_w_supervision_try2.h5') # Saving the compile weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to plot the accuracy and loss result of the model during the training.\n",
    " \n",
    "Loss value implies how poorly or well a model behaves after each iteration of training.\n",
    "\n",
    "Accuracy is a metric that can be applied to classification tasks only. It describes just what percentage of your train/test data are classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1600740443959,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "PxFBEdKJg36i"
   },
   "outputs": [],
   "source": [
    "# This function generates graphs of the loss and the accuracy of the model\n",
    "def plotVal_plotLoss (model) :\n",
    "\n",
    "    plt.plot(model.history['acc'])\n",
    "    plt.plot(model.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('loss_plot_4 (simulated vgg1)2')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(model.history['loss'])\n",
    "    plt.plot(model.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('loss_plot_4 (simulated vgg1)2')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "```\n",
    "Now we are ready to start the training\n",
    "\n",
    "Define the image size for the dataset and batch size for the PrepareData function\n",
    "img_width, img_height = 197, 197\n",
    "batch_size = # The batch size represents the total amount of images that are included in each iteration.\n",
    "\n",
    "\n",
    "Define the image size and the learning rate for compileModel function\n",
    "model=compileModel(img_width, img_height,learning_rate=1e-4)\n",
    "\n",
    "Define the total amount of samples in both the training and validation set\n",
    "nb_train_samples = #add code\n",
    "nb_validation_samples =#add code\n",
    "epochs = #add code\n",
    "trainModel(train_data, validation_data, model)\n",
    "\n",
    "You can varies the batch_size, epochs to understand the impact on the model accuracy and loss values\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159950,
     "status": "ok",
     "timestamp": 1600741556038,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "RXNggLb7g4MG",
    "outputId": "7e0f3b08-0ce6-4028-9067-4ddb8b04d6e5"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 197,197\n",
    "\n",
    "# The batch size represents the total amount of pictures that are included in each iteration.\n",
    "batch_size = 30\n",
    "\n",
    "#Prepare data\n",
    "train_data, validation_data = PrepareData(img_width,img_height,batch_size)\n",
    "\n",
    "#Load Model\n",
    "model=model=compileModel(img_width, img_height,learning_rate=1e-4)\n",
    "\n",
    "# Defining the total amount of samples in both the training and validation set\n",
    "nb_train_samples = 180\n",
    "nb_validation_samples = 45\n",
    "epochs = 1\n",
    "\n",
    "#Start the training model\n",
    "trainModel(train_data, validation_data, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBdPXDexTSsX"
   },
   "source": [
    "# 6. Use the trained model to classify input data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Setup a predict image function\n",
    "\n",
    "In the prediction function, we will read in an image and resize it to be the same size(width and height) as the trained model input. Then pass it into the model for prediction, the predicted result will be represented with the label name. In our case will the car model names(Honda, Toyota, Volkswagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1600740763311,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "o_hvMM66goEz"
   },
   "outputs": [],
   "source": [
    "# This function c\n",
    "def predictImg(path, model):\n",
    "    imagep = image.load_img(path, target_size=(197, 197))\n",
    "    x = image.img_to_array(imagep)\n",
    "    x = x / 255  # Insures that images are normalized, so it can be compared test on a model that also used normalized training and validation images\n",
    "\n",
    "    x = np.expand_dims(x, axis=0) # flattens the image\n",
    "    prediction = model.predict(x) # Extract the prediction made by the model\n",
    "    print(path)\n",
    "    print(prediction)\n",
    "    findLabel(prediction, 0.2, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1600740765510,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "b3efmUz5gxsj"
   },
   "outputs": [],
   "source": [
    "def findLabel(test, threshold, path):\n",
    "    if (max(test[0]) < threshold):\n",
    "        print(\"no class could be defined for \" + path + \" with threshold 0.85\")\n",
    "    else:\n",
    "        m = max(test[0])\n",
    "        index = [i for i, j in enumerate(list(test[0])) if j == m]\n",
    "        labeler(index[0], path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1600740774631,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "0trRjR9pgx_j"
   },
   "outputs": [],
   "source": [
    "def labeler(inp, pathname):\n",
    "    label = list(classes.keys())[inp]\n",
    "    print(\"The image '\" + pathname + \"' belongs to class: \" + label) # Prints the prediction\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now we are ready to use the trained model to predict the image.\n",
    "\n",
    "Load our Resnet50 CNN model with the trained values. The trained values are stored in the .h5 file.\n",
    "\n",
    "Pass the image and the trained model to the prediction function.\n",
    "\n",
    "Try with different image from different car model and check the predicted result again the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60167,
     "status": "ok",
     "timestamp": 1600742011234,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "LRPFxU8PhC-6",
    "outputId": "f5ad104c-cd36-4906-e187-0d6afcc49a34"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 197, 197\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "img_width, img_height = 197, 197\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "model = compileModel(img_width, img_height)\n",
    "\n",
    "model.load_weights(data_dir_path+'custom_w_supervision_try2_best.h5')\n",
    "\n",
    "predictImg(prediction_data_dir + '/toyota1.jpg', model) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkruaBc4pLdY0qKoXWG6qt",
   "name": "Car3_Classification_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
