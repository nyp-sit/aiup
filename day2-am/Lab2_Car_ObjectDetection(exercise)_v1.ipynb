{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./doc_images/nyplogo.jpg\">\n",
    "Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n",
    "\n",
    "1. The notebook is composed of cells; cells can contain code which you can run, or they can hold text and/or images which are there for you to read.\n",
    "\n",
    "2. You can execute code cells by clicking the ```Run``` icon in the menu, or via the following keyboard shortcuts ```Shift-Enter``` (run and advance) or ```Ctrl-Enter``` (run and stay in the current cell).\n",
    "\n",
    "3. To interrupt cell execution, click the ```Stop``` button on the toolbar or navigate to the ```Kernel``` menu, and select ```Interrupt ```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7kdWxWYoOtS"
   },
   "source": [
    "# **Lab 2 Car Object Detection**\n",
    "\n",
    "In this Lab we will try to build a car object detector to helps in the recognition, detection, and localization of multiple visual car instances in an image.\n",
    "\n",
    "The main concept behind this process is that every object will have its features. These features can help us to segregate objects from the other ones. Object detection uses these features to classify the objects. And also predict the classified object localization with a 2 dimension bounding box.\n",
    "\n",
    "\n",
    "![image](https://www.linkpicture.com/q/object-detection-introduction.png)\n",
    "\n",
    "\n",
    "Similar to the Classification problem, we need to collect the data. We will collect images that contain different types of cars and provide the label. For Object Detection problem we also need to annotate the location of the car in the images to be part of the label. With the prepared dataset, we can do training with the defined Object Detection model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will build the car object detection  based on the following steps\n",
    "\n",
    "1.   Collect images for the class car\n",
    "2.   Annotate each of the objects inside the image \n",
    "3.   Train the model with the training set and evaluate it performance\n",
    "4.   Prediction using trained model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAdHp9orDa6_"
   },
   "source": [
    "# **1. Collect images for the class car**\n",
    "\n",
    "Collect about 25 images of car. Prepare into test and valiation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "```\n",
    "In the VM path ./dataset/Lab2dataset/\n",
    "\n",
    "create create the following directory structure\n",
    "./dataset/Lab2dataset/\n",
    "   |- train\n",
    "       |- annotations\n",
    "       |- images\n",
    "   |- validation \n",
    "       |- annotations\n",
    "       |- images\n",
    "```\n",
    "\n",
    "```\n",
    "Goto Google website, search for images of car. \n",
    "Download 20 car images into local computer in a train folder\n",
    "Download 5 car images into local computer in a validation folder\n",
    "```\n",
    "```\n",
    "From the local computer train folder copy the 20 car images into VM ./dataset/Lab2dataset/train/images\n",
    "\n",
    "From the local computer validation folder copy the 5 car images into VM ./dataset/Lab2dataset/validation/images\n",
    "\n",
    "Let explore the images we had collected in the VM train dataset.\n",
    "\n",
    "Try to display different images with the following code.\n",
    "\n",
    "What do you notice about the images? Are your car images content about same content or there are diversity eg. different type of car, multiple cars in a single image.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23414,
     "status": "ok",
     "timestamp": 1600853236621,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "KhTgJj138RC4",
    "outputId": "69c61f95-5c94-47a6-d9f0-acf69ca4eaf5"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir_path='./dataset/Lab2dataset/'\n",
    "data_path_train_images='./dataset/Lab2dataset/train/images/'\n",
    "data_path_validation_images='./dataset/Lab2dataset/validation/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(#add code - train path and image file name)\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ds3nszHmDtys"
   },
   "source": [
    "# **2. Annotate each of the objects inside the image**\n",
    "\n",
    "In this section we will prepare the collected image label. With the help of the LabelImage utility we will label name of the object and the 2 dimension bounding box parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Download the LabelImage utility from https://tzutalin.github.io/labelImg/ into Lab local drive.\n",
    "\n",
    "In Lab Computer local drive , run LabelImage.exe\n",
    "\n",
    "Perform the annoatation with the images store in the train and validation directories.\n",
    "\n",
    "Output of annotation will be the image files with the corresponding xml files\n",
    "\n",
    "\n",
    "[![image](https://www.linkpicture.com/q/labelimage.png)\n",
    "\n",
    "\n",
    "In the utility browse through each image in the local drive directory, annotate the car object by drawing a bounding box. A correspond XML file will be generated for each image.\n",
    "\n",
    "\n",
    "Transfer all the local drive XML file into the VM\n",
    "\n",
    "After completed all the annotation for train images in local drive train folder, copy all the XML files into the VM annotation directories ./dataset/Lab2dataset/train/annotations\n",
    "\n",
    "After completed all the annotation for validation images in local drive validation folder, copy all the XML files into the VM annotation directories ./dataset/Lab2dataset/validation/annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHfoQbCRGjfQ"
   },
   "source": [
    "# **3. Train the model with the training set and evaluate it performance**\n",
    "\n",
    "YOLO is very popular because it achieves high accuracy while also being able to run in real-time. The algorithm “only looks once” at the image in the sense that it only requires the image or the video to pass through the neural network once to make predictions.\n",
    "\n",
    "With YOLO, a single CNN simultaneously predicts multiple bounding boxes and class probabilities for those boxes. This basically means they recognize where the object is at and uses bounding boxes to show where it is at, and uses class probability to determine what the object is.\n",
    "\n",
    "\n",
    "[![image](https://www.linkpicture.com/q/yolo_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fks1o7zc83IX"
   },
   "source": [
    "### Execrise\n",
    "\n",
    "In this exercise we are going to define the Custom YOLO Object Detection model and perform training.\n",
    "\n",
    "We will reuse a YOLO pre-trained model in our problem, this is also known as transfer learning. Transfer learning exploits the knowledge gained from a previous task to improve generalization about another. \n",
    "\n",
    "\n",
    "1.   Import the imageai module. This module provides a YOLO model that can be trained with our custom dataset\n",
    "\n",
    "```\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "```\n",
    "\n",
    "2.   Set the path to the image dataset we want to train the network on\n",
    "```\n",
    "trainer.setDataDirectory(data_directory=data_dir_path)\n",
    "```\n",
    "3.   Configured our YOLO object detection model \n",
    "```\n",
    "trainer.setTrainConfig(object_names_array=[#add code], batch_size=#add code, num_experiments=#add code, train_from_pretrained_model=car_dir_path+\"pretrained-yolov3.h5\")\n",
    "```\n",
    "\n",
    "    *   object_names_array : this is an array containing the names of the objects in our dataset(in our case we labeled it car)\n",
    "    *   batch_size : this is to state the batch size for the training\n",
    "    *   num_experiments : this is to state the number of times the network will train over all the training images, which is also called epochs\n",
    "    *   train_from_pretrained_model : this is to train using transfer learning from a pre-trained YOLOv3 model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4.    start the training, you should see something like this in the console\n",
    "```\n",
    "trainer.trainModel()\n",
    "```\n",
    "\n",
    "Observe the training loss result by applying different batch size and epoch(num_experiements).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FrVHH-Ha9CVl",
    "outputId": "11ce3c80-fc36-4cec-d503-d0b51a9543d0"
   },
   "outputs": [],
   "source": [
    "#1.\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "#2.\n",
    "# car_dir_path= data_dir_path\n",
    "trainer.setDataDirectory(data_directory=data_dir_path)\n",
    "#3.\n",
    "trainer.setTrainConfig(object_names_array=[#add code], batch_size=#add code, num_experiments=#add code, train_from_pretrained_model=#add code)\n",
    "\n",
    "#4.\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iX-LsyOFHnup"
   },
   "source": [
    "# 4. Prediction using trained model\n",
    "\n",
    "1.   Import the ImageAI custom YOLO object detection class, created the class instance\n",
    "```\n",
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "detector = CustomObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "```\n",
    "\n",
    "\n",
    "2.   Specified the file path to our custom trained model file and specified the path to detection_config.json file\n",
    "```\n",
    "car_dir_path= data_dir_path\n",
    "detector.setModelPath(#add code- path and trained model file name)\n",
    "detector.setJsonPath(data_dir_path+\"json/detection_config.json\")\n",
    "```\n",
    "3.   loaded the model\n",
    "```\n",
    "detector.loadModel()\n",
    "```\n",
    "\n",
    "\n",
    "4.   Run the detectObjectsFromImage() function and parse in the path to our test image, and the path to the new image which the function will save\n",
    "```\n",
    "detections = detector.detectObjectsFromImage(input_image=#add code, output_image_path=#add code)\n",
    "```\n",
    "\n",
    "5. Then the function returns an array of dictionaries with each dictionary corresponding to the number of objects detected in the image. Each dictionary has the properties name (name of the object), percentage_probability (percentage probability of the detection) and box_points (the x1,y1,x2 and y2 coordinates of the bounding box of the object).\n",
    "\n",
    "The label name shows the object being classified and the probability displayed how confidence the object being predicted. And the box points show the localization of the object using the bottom left coordinate and the upper right coordinate to form a bounding box.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "We will use the trained YOLO object detection model to do this exercise. Defined the trained model file, the input images for prediction and the output image to store the predicted result. Run the prediction and observe the result label name, probability and box_points.\n",
    "\n",
    "Try with different images and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15890,
     "status": "ok",
     "timestamp": 1600854038207,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "jBTP2vr0Hubs",
    "outputId": "c6f5fb01-bdcf-4e07-9ac5-13fbffdb2458"
   },
   "outputs": [],
   "source": [
    "#1\n",
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "detector = CustomObjectDetection()\n",
    "#2\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "#3\n",
    "detector.setModelPath(#add code)\n",
    "detector.setJsonPath(data_dir_path+\"json/detection_config.json\")\n",
    "#4\n",
    "detector.loadModel()\n",
    "#5\n",
    "detections = detector.detectObjectsFromImage(input_image=#add code, output_image_path=#add code)\n",
    "#6\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3076,
     "status": "ok",
     "timestamp": 1600854071904,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "PKPKBwYyEpuS",
    "outputId": "7f4e2f6b-96c2-4375-a6f1-d51b61d23fe2"
   },
   "outputs": [],
   "source": [
    "detections = detector.detectObjectsFromImage(input_image=hololens_dir_path+\"image5.jpg\", output_image_path=hololens_dir_path+\"image5-detected.jpg\")\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM+0kFKqv5vdeYNERkCEuvP",
   "name": "Lab3_Car_ObjectDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
