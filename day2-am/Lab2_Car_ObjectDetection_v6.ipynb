{"cells":[{"cell_type":"markdown","metadata":{"id":"Fc04bXLRbar9"},"source":["\n","![image](https://drive.google.com/uc?id=1iBMNGCrSdaLK9SD6BjsuNjB1DjHVkLZl)\n","\n","\n","Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n","\n","1. The notebook is composed of cells; cells can contain code which you can run by click on the play button.\n","\n","\n","2. To interrupt cell execution, click the ```Stop``` button on the side of the cell."]},{"cell_type":"markdown","metadata":{"id":"p7kdWxWYoOtS"},"source":["# **Lab 2(solution) Car Object Detection**\n","\n","In this Lab we will try to build a car object detector to helps in the recognition and localization of multiple car instances in an image.\n","\n","The predicted output from the object detector will the label of the object and the bounding box to denote the location of the object. In the following, you can see an example of the object detector predicted 2 objects with label vehicle and 2 bounding boxes to indicate the objects' location.\n","\n","![image](https://drive.google.com/uc?id=1a8Wr4zlQ7cXVtxx7y4xTeVzVMOPD_GDg)\n","\n","\n","Similar to the Classification problem, we need to collect the data for training. We will collect images that contain cars and provide labels. For Object Detection problem we also need to annotate the locations of the cars in the images to be part of the label. With the prepared dataset, we can do training with the Object Detection neural network.\n","\n","\n","\n","\n","\n","The car object detector is built based on the following steps\n","\n","1.   Collect images for the class car\n","2.   Annotate each of the objects inside the images\n","3.   Train the model with the training set and evaluate it performance\n","4.   Prediction using trained model\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RWII5GZsvQVs"},"source":["Install modules\n","\n","**There are some modules incompatibility but we are not using it. When encounter the error just press restart runtime and continue next cell**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkRmcHc9fHes"},"outputs":[],"source":["\n","!pip install imageai\n"]},{"cell_type":"markdown","metadata":{"id":"DAdHp9orDa6_"},"source":["# **1.Use the pretrained Object Detection model to detect the Car in the Image**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"T8lGvVuyvoep"},"source":["Download  pretrained Object Detection model"]},{"cell_type":"code","source":["!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/3.0.0-pretrained/retinanet_resnet50_fpn_coco-eeacb38b.pth"],"metadata":{"id":"2mMpGwoBs2mZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Download the image for object detection"],"metadata":{"id":"aIx8QL-ztKfO"}},{"cell_type":"code","source":["!gdown 1Sp8eG0MI6Jx7eiPD9U29roJhyBVpNOgA"],"metadata":{"id":"y4_W3UuSs6xD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tHfoQbCRGjfQ"},"source":["\n","\n","Example of a Object Detection Model - Yolo\n","\n","YOLO(Your Only Look Once) is very popular because it achieves high accuracy while also being able to run in real-time. The algorithm “only looks once” at the image in the sense that it only requires the image or the video to pass through the neural network once to make predictions.\n","\n","With YOLO, a single CNN simultaneously predicts multiple bounding boxes and class probabilities for those boxes. This means they recognize where the object is at and uses bounding boxes to show where it is at, and uses class probability to determine what the object is.\n","\n","\n","![image](https://drive.google.com/uc?id=16IMqEc7bhPz0zPE-iD2SosFqA0hgK5kb)\n"]},{"cell_type":"markdown","source":["\n","\n","*   Load the pretrained Object Detection Model\n","*   Pass an image for object detection into the Model\n","*   The model will return the classification label and bounding box\n","\n","\n"],"metadata":{"id":"QQXKM6X_ta-9"}},{"cell_type":"code","source":["from imageai.Detection import ObjectDetection\n","import os\n","\n","execution_path = os.getcwd()\n","\n","detector = ObjectDetection()\n","detector.setModelTypeAsRetinaNet()\n","detector.setModelPath( os.path.join(execution_path , \"retinanet_resnet50_fpn_coco-eeacb38b.pth\")) # Download the model via this link https://github.com/OlafenwaMoses/ImageAI/releases/download/3.0.0-pretrained/retinanet_resnet50_fpn_coco-eeacb38b.pth\n","detector.loadModel()\n","detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"cars.jpg\"), output_image_path=os.path.join(execution_path , \"2_detected.jpg\"), minimum_percentage_probability=40)\n","\n","for eachObject in detections:\n","    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n","    print(\"--------------------------------\")"],"metadata":{"id":"yB_L0A93tWpO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Display the result of the object detection image"],"metadata":{"id":"_MhCxTBBuwhK"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","img = mpimg.imread(\"2_detected.jpg\")\n","plt.imshow(img)"],"metadata":{"id":"s5zX71XtuWeC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ds3nszHmDtys"},"source":["# **2. .Use the pretrained Object Detection model to detect the Car in the Video**\n","\n","In this section we will try to practice how to use pretrained object detection model to detect the objects in the video.\n"]},{"cell_type":"markdown","source":["Download a pretrained object detection model"],"metadata":{"id":"VXj9xkeSvb9r"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FrVHH-Ha9CVl"},"outputs":[],"source":["!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/3.0.0-pretrained/yolov3.pt"]},{"cell_type":"markdown","source":["Download a video to do object detection"],"metadata":{"id":"mlWX__wuvrny"}},{"cell_type":"markdown","source":[],"metadata":{"id":"1lvywJ_wwuNQ"}},{"cell_type":"code","source":["!gdown 1G2o-jSwK9O4ir8hL5MSKRX_M5CeF0uUs"],"metadata":{"id":"4TvV2pWLwMbU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","*   Load Object Detection pretrained model\n","*   Input the video for object detection model\n","*   The model wil predict the object in each of the frame extracted from the video\n","\n","\n"],"metadata":{"id":"fBPXdjJwwQFe"}},{"cell_type":"code","source":["from imageai.Detection import VideoObjectDetection\n","import os\n","\n","execution_path = os.getcwd()\n","print(execution_path)\n","\n","detector = VideoObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath(os.path.join(execution_path, \"yolov3.pt\")) # https://github.com/OlafenwaMoses/ImageAI/releases/download/3.0.0-pretrained/yolov3.pt\n","# detector.setModelPath(\"yolov3.pt\")\n","detector.loadModel()\n","\n","# custom = detector.CustomObjects(person=True, car=True, bus=True)\n","video_path = detector.detectObjectsFromVideo(input_file_path=os.path.join(execution_path, \"traffic-mini.mp4\"),\n","                                output_file_path=os.path.join(execution_path, \"traffic_detected\")\n","                                , frames_per_second=20, log_progress=True)\n","print(video_path)"],"metadata":{"id":"LwdVds_zwJ8E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the video which had complete the object detection"],"metadata":{"id":"kSdnTwUfxLll"}},{"cell_type":"code","source":["from moviepy.editor import VideoFileClip\n","\n","# Define video path\n","video_path = 'traffic_detected.mp4'\n","\n","# Load and display video\n","video = VideoFileClip(video_path)\n","video.ipython_display(width=640, autoplay=True)"],"metadata":{"id":"GzKzPpp2xWkB"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}