{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.linkpicture.com/q/nyplogo.jpg)\n",
    "\n",
    "Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n",
    "\n",
    "1. The notebook is composed of cells; cells can contain code which you can run, or they can hold text and/or images which are there for you to read.\n",
    "\n",
    "2. You can execute code cells by clicking the ```Run``` icon in the menu, or via the following keyboard shortcuts ```Shift-Enter``` (run and advance) or ```Ctrl-Enter``` (run and stay in the current cell).\n",
    "\n",
    "3. To interrupt cell execution, click the ```Stop``` button on the toolbar or navigate to the ```Kernel``` menu, and select ```Interrupt ```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFoLOed-Vm5R"
   },
   "source": [
    "# Lab 1 : Car Model Classification with CNN\n",
    "In this lab we will try to build a Vehicle Classifier to classify three different models of the car. We will collect 3 groups of images namely  Honda Civic, Toyota Altis and Volkswagen Passat to be our dataset. The  collected dataset will be used to train the Resnet50 CNN(Convolution Neural Network). Upon completion of the training, we will be able to classify an unknown image to give a prediction of the model of the car.  \n",
    "\n",
    "\n",
    "We will build the car model classifier based on the following steps\n",
    "\n",
    "1.   Select the python virtual environment   \n",
    "2.   Import the libraries needed for the program\n",
    "3.  Prepare the data\n",
    "4.   Prepare the CNN model\n",
    "5.  Train the model with the training set and evaluate its performance\n",
    "6.   Use the trained model to classify input data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gr9UQHf5JwE3"
   },
   "source": [
    "# 1. Select the python virtual environment\n",
    "\n",
    "At the upper right corner of the jupyter notebook, select the pre-installed python virtual environment.\n",
    "Look for python virtual environment with the name tf1env. Select this for our lab exercise. \n",
    " \n",
    " \n",
    " ![image](https://www.linkpicture.com/q/tf1env.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj1dHMgCLr9a"
   },
   "source": [
    "# 2. Import the libraries needed for the program\n",
    "We will begin by importing the libraries that we need, mainly Keras.  \n",
    "Keras is based on a minimal framework that provides a simpler way to create deep learning models based on TensorFlow.\n",
    "Keras contains useful functions for pre-preprocessing of image data and definition of convolution neural network.\n",
    "Matplotlib is used for data visualization. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2369,
     "status": "ok",
     "timestamp": 1600739644086,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "LjhErGYmV2Qi",
    "outputId": "129e7331-85da-4362-9c7d-4fc502d1be67"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers, regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1600739647808,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "EAx4b2JXiWYm",
    "outputId": "e8e8bc65-31a7-46ae-836a-ff427ed175ae"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhr5JMTPMBlo"
   },
   "source": [
    "# 3. Prepare the data\n",
    "\n",
    "Usually in ML, we divide our data into 3 different sets\n",
    "\n",
    "- Training Data: Collection of sample data used to train the neural network.\n",
    "\n",
    "- Validation Data: Collection of sample data used to provide an unbiased evaluation of neural netowork during the training.\n",
    "\n",
    "- Test Data: Collection of sample data used to evaluate the trained neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJqGwgQNaDf"
   },
   "source": [
    "### 3.1 Collect data for training and validation\n",
    "\n",
    "We have pre-collected data that are stored in the following directory structure.\n",
    "\n",
    "For train data, it store in the path ./dataset/Lab1dataset/data/train.\n",
    "```\n",
    "./dataset/Lab1dataset/data/train\n",
    "                           |- Honda\n",
    "                           |- Toyota\n",
    "                           |- Volkswagen \n",
    "\n",
    "```\n",
    "Each of the above sub-directories(Honda, Toyota, Volkawagen) is stored with\n",
    "60 different jpg images.\n",
    "\n",
    "\n",
    "For validation data, it store in the path ./dataset/Lab1dataset/data/validation.\n",
    "```\n",
    "./dataset/Lab1dataset/data/validation.\n",
    "                               |- Honda\n",
    "                               |- Toyota\n",
    "                               |- Volkswagen \n",
    "```\n",
    "Each of the above sub-directories(Honda, Toyota, Volkawagen) is stored with\n",
    "15 different jpg images.\n",
    "\n",
    "\n",
    "For test data, it store in the path /dataset/Lab1dataset/prediction_images\n",
    "```\n",
    "./dataset/lab1dataset/\n",
    "    |- prediction_images\n",
    "\n",
    "```\n",
    "A few test images are stored in the above test directory.\n",
    "\n",
    "\n",
    "Start the terminal. Use the follow command to copy the dataset for the lab\n",
    "```\n",
    "cp -rf dataset ~/git/mindef-ai/day2-am\n",
    "```\n",
    "\n",
    "![image](https://www.linkpicture.com/q/terminal.jpg)\n",
    "\n",
    "\n",
    "We will define the following variables for the different data path.\n",
    "\n",
    "It will be easier for us to reference these paths in other sections of the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1208,
     "status": "ok",
     "timestamp": 1600739785215,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "UqJN2hz7ZUy_"
   },
   "outputs": [],
   "source": [
    "# Define train data paths, validation data path and test data path \n",
    "data_dir_path='./dataset/Lab1dataset/data/'\n",
    "train_data_dir = data_dir_path+'train/'\n",
    "validation_data_dir = data_dir_path+'validation/'\n",
    "prediction_data_dir = './dataset/Lab1dataset/prediction_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Let explore the images we had collected for the train dataset.\n",
    "\n",
    "Display the following images from the train data.\n",
    "\n",
    "* image 1 ( train_data_dir+\"Honda/100.jpg\")\n",
    "* image 2 (  train_data_dir+\"Toyota/Altis.jpg\")\n",
    "\n",
    "What do you notice about the size of each of the image?\n",
    "Read the printed image size (with, height, color).\n",
    "\n",
    "*color(1-greysacle, 3-color)\n",
    "\n",
    "Why are we interested in the image size?\n",
    "\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "    \n",
    "The Convolution Neural Network(CNN) has a fixed data input size. Therefore we need to pre-process the collected images to the same size as the CNN input before we can do training.\n",
    "    \n",
    "<br/>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# TODO: complete the code below\n",
    "#image 1\n",
    "# img = mpimg.imread(#add code)\n",
    "print(img.shape)\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the code below\n",
    "#image 2\n",
    "# img = mpimg.imread(#add code)\n",
    "print(img.shape)\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDuVmIyrSoFe"
   },
   "source": [
    "### 3.2 Prepare Data for training and validation\n",
    "\n",
    "From the previous exercise, we noticed that the collected data need to be pre-processed before we can use it to train our CNN. In this section, we will look at some of the methods that can help us to do data pre-processing.\n",
    "\n",
    "Data augmentation is a strategy that enables developer to significantly increase the diversity of data available through data pre-processing.\n",
    "\n",
    "Data augmentation techniques such as resizing, rotation, and cropping are commonly used to train large neural networks.\n",
    "\n",
    "\n",
    "![image](https://www.linkpicture.com/q/Augmentation.png)\n",
    "\n",
    "Kera provides us a function to do data augmentation. We can configure the parameters in the function to achieve the required image pre-processing. We will do some of the parameters configuration in the exercise.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "We will configure the image augmentation parameters in the Keras ImageDataGenerator() function for the train and validation data.\n",
    "\n",
    "Here are some for the parameters.\n",
    "\n",
    "- rescale factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided. Most of the time we rescale based on the greyscale eg. 1./255\n",
    "\n",
    "- shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees) eg. 0.2 degrees\n",
    "\n",
    "- zoom_range: Float. zoom range for width and height. eg. 0.2\n",
    "\n",
    "- horizontal_flip: Boolean. Randomly flip inputs horizontally.eg. True\n",
    "\n",
    "- add the configuration value in the area #add code \n",
    "\n",
    "\n",
    "After complete the data argumentation parameters, observe the paremeter *target_size* in the function train_datagen.flow_from_directory() and validation_datagen.flow_from_directory.\n",
    "\n",
    "Which of the target_size should we choose for the data pre-processing?\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "As mentioned previously, Convolution Neural Network(CNN) has a fixed data input size. Therefore we need to set the target_size to be the same as the CNN input size for the pre-processing. We are not able to know the size until we have setup the ResNet50 CNN input.\n",
    "    \n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "\n",
    "We will put the above pre-processing steps for train and validation inside the function name PrepData().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Data for training and validation\n",
    "\n",
    "def PrepareData(img_width,img_height,batch_size ):\n",
    "\n",
    "    # This augments the data. This is usefull when working with a small sample size\n",
    "    # TODO: complete the code below\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale= #add code,\n",
    "        shear_range= #add code,\n",
    "        zoom_range= #add code,\n",
    "        horizontal_flip= #add code)\n",
    "    \n",
    "    # TODO: complete the code below\n",
    "    validation_datagen = ImageDataGenerator(rescale=#add code)\n",
    "\n",
    "    print(\"train generator\")\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"validation generator\")\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "    return train_generator,validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6KWkyz_PjU3"
   },
   "source": [
    "### 3.3 Get the total number of predicted classes/labels\n",
    "\n",
    "The label of the training samples are determined by the subdirectory name, e.g.In the train sub-directories, Honda is the label to tag to all the images collected for that group.\n",
    "\n",
    "In our case, the number of predicted classes are based on the numbers of sub-directories in the train folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "We are going to find the number of classes and the labels for our collected data.\n",
    "\n",
    "Where can we get the information for the number of classes and the Label names?\n",
    "Look for the directory where we stored our train data. Complete the following code. \n",
    "\n",
    "Observe the number of classes printed at the output. Why we need to determine the number of classes?\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "    \n",
    "The Convolution Neural Network(CNN) has a fixed data input size and output size. We have pre-processed our data for CNN input,next we need to handle the CNN output. \n",
    "\n",
    "The number of classes is to allow the CNN to predict the number of outputs.\n",
    "    \n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the total no. of classes and labels\n",
    "\n",
    "# TODO: complete the code below -what is the directory of the train data\n",
    "classes = ImageDataGenerator().flow_from_directory(#add code).class_indices\n",
    "print(classes)\n",
    "print(\"number of classes=\"+ str(len(classes)))\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QO0RcRNQSS0-"
   },
   "source": [
    "# 4. Prepare the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3-_hKmxN20M"
   },
   "source": [
    "### 4.1 CNN Convolution Netural Network\n",
    "\n",
    "\n",
    "![image](https://www.linkpicture.com/q/resnet50.png)\n",
    "\n",
    "There are many CNN implementation, such as LeNet, AlexNet, VGG, GoogLeNet, ResNet and more.\n",
    "\n",
    "In this lab we will be using ResNet50 CNN.\n",
    "\n",
    "The ResNet50 is built from the different combination of the following layers\n",
    "        *   Conv2D-> number of feature maps, feature map size (width x height)\n",
    "        *   Activation function -> relu , sigmoid \n",
    "        *   MaxPooling-> kernel size (width x height)\n",
    "\n",
    "together with the output layers\n",
    "\n",
    "        *   Flatten-> 2D to 1D\n",
    "        *   Dense layer->number of neutrons\n",
    "        *   Activation Function->softmax(probability of each the classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execrise\n",
    "We have a brief understanding of how the ResNet50 layers are formed. In this exercise, we will customised our ResNet50 to train our pre-process dataset.\n",
    "\n",
    "Set the ResNet50 input size.\n",
    "- In the following code, goto function ResNet50() set the parameters input_size to (width,height,color)->(197,197,3)\n",
    "\n",
    "Recall in the earlier exercise, we have 3 different classes of images. We need our CNN to be able to predict these 3 classes. What do you think how many output neurons of the last Dense layer should have? \n",
    "\n",
    "- In the following codes, change the dense layer numbers of neurons according to the number of classes. \n",
    "\n",
    "Run the function compileModel() to build the custom ResNet50.\n",
    "\n",
    "Observe the print out of the customise ResNet50. Look for the input size. What is input size?\n",
    "\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "    \n",
    "We have fixed our customise ResNet50 with the input size (197,197,3), this will be the size we need to set for the pre-processing of our data.\n",
    "\n",
    "    \n",
    "<br/>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileModel():\n",
    "    print(\"compiling model\")\n",
    "    learning_rate=1e-4\n",
    "\n",
    "     ## TODO: Add in the input size\n",
    "    conv_base = ResNet50(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(#add code, #add code, #add code))\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    #Add dense and classification layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    \n",
    "    ## TODO: Change the Dense layer to have the correct number of classes \n",
    "    model.add(layers.Dense(#add code, activation='softmax'))\n",
    "\n",
    "    print(conv_base.summary())\n",
    "    print(model.summary())\n",
    " \n",
    "    model.compile(loss='categorical_crossentropy',optimizer= optimizers.adam(lr=learning_rate),metrics=['accuracy'])\n",
    "    for layer in conv_base.layers:\n",
    "      layer.trainable = False\n",
    "    for layer in conv_base.layers[-4:]:\n",
    "      layer.trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compileModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ResNet50 CNN will go through many iterations during training. We will set a checkpoint to save the best-trained model during the training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1523,
     "status": "ok",
     "timestamp": 1600740131384,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "zMUegDZ9gY62"
   },
   "outputs": [],
   "source": [
    "best_model = keras.callbacks.ModelCheckpoint(data_dir_path+'custom_w_supervision_try2_best' + '.h5', monitor='val_acc',save_best_only=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss',factor=0.25, patience=5,min_lr=0.000005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAFGrHhTTIWX"
   },
   "source": [
    "# 5. Train the model with the training set and evaluate it performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1V4dlZyHUVTM"
   },
   "source": [
    "### 5.1 Train and validate the model\n",
    "\n",
    "\n",
    "![image](https://www.linkpicture.com/q/training.png)\n",
    "\n",
    "With the preprocessed training and validation dataset. We can input them into the our defined model for training.\n",
    "As part of the training, we will also need to set some parameter values in the training function (the ``fit()``)\n",
    "\n",
    "- Set the number of epoch to  indicates the number of passes of the entire training dataset the model has to complete.\n",
    "\n",
    "- When we have a huge data set it not possible to load the entire data to run one epoch of training. Setting Step per epoch allow huge data to divide into batches to complete entire training.\n",
    "\n",
    "We save the final training iteration weights into to a binary data format(.h5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1600740440814,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "Nf9oc01xgnos"
   },
   "outputs": [],
   "source": [
    "def trainModel(train_data, validation_data,model):\n",
    "\n",
    "    print(\"starting training.... \")\n",
    "    hist = model.fit_generator(\n",
    "        (train_data),\n",
    "        steps_per_epoch=nb_train_samples // batch_size, # The accumulated amount of steps\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_data,\n",
    "        nb_val_samples=nb_validation_samples,\n",
    "        callbacks=[best_model, reduce_lr]\n",
    "    )\n",
    "\n",
    "    plotVal_plotLoss(hist)\n",
    "    model.save_weights(data_dir_path+'custom_w_supervision_try2.h5') # Saving the compile weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following function plotVal_plotLoss() is to plot the accuracy and loss result of the model during the training.\n",
    " \n",
    "- Loss is a number that indicates the difference between the model's prediction output with the ground truth. \n",
    "\n",
    "- Accuracy is a metric that can be applied to classification tasks only. It describes just what percentage of your train/test data are classified correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1600740443959,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "PxFBEdKJg36i"
   },
   "outputs": [],
   "source": [
    "# This function generates graphs of the loss and the accuracy of the model\n",
    "def plotVal_plotLoss (model) :\n",
    "\n",
    "    plt.plot(model.history['acc'])\n",
    "    plt.plot(model.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('loss_plot_4 (simulated vgg1)2')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(model.history['loss'])\n",
    "    plt.plot(model.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('loss_plot_4 (simulated vgg1)2')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now we are ready to start the training\n",
    "\n",
    "Define the image size for the dataset and batch size for the PrepareData() function\n",
    "\n",
    "```\n",
    "img_width, img_height = 197, 197\n",
    "batch_size = # The batch size represents the total amount of images that are included in each iteration.\n",
    "```\n",
    "Why is the image size needed to pre-process the image is 197,197? \n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "    \n",
    "We have fixed our customise ResNet50 with the input size (197,197,3), this will be the size we need to set for the pre-processing of our data.\n",
    "\n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "    \n",
    "     \n",
    "Define the total amount of samples for the training and validation set.\n",
    "\n",
    "In the previous step we have copied the dataset for the lab, we have mentioned the amount of data that are stored in the dataset.\n",
    "```\n",
    "nb_train_samples = #add code\n",
    "nb_validation_samples =#add code\n",
    "```\n",
    "\n",
    "Set the number of epoch(iterations) to conduct the training\n",
    "```\n",
    "epochs = #add code\n",
    "\n",
    "```\n",
    "You can varies the epochs to observe the model accuracy and loss values.\n",
    "\n",
    "What do you notice when epochs are varied?\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "Typically the increase in the epochs will reduce the loss and improve the prediction accuracy.    \n",
    "\n",
    "<br/>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159950,
     "status": "ok",
     "timestamp": 1600741556038,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "RXNggLb7g4MG",
    "outputId": "7e0f3b08-0ce6-4028-9067-4ddb8b04d6e5"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "## TODO: Set the image width and height \n",
    "img_width, img_height = #add code, #add code\n",
    "\n",
    "# The batch size represents the total amount of pictures that are included in each iteration.\n",
    "## TODO: Set the batch size\n",
    "batch_size = 30\n",
    "\n",
    "#Prepare data\n",
    "train_data, validation_data = PrepareData(img_width,img_height,batch_size)\n",
    "\n",
    "#Load Model\n",
    "model=model=compileModel()\n",
    "\n",
    "# Defining the total amount of samples in both the training and validation set\n",
    "## TODO: Set the total nunmber of train images and total number of validation images\n",
    "nb_train_samples =#add code\n",
    "nb_validation_samples =#add code\n",
    "\n",
    "## TODO: Set the number to training iterations\n",
    "epochs = #add code\n",
    "\n",
    "#Start the training model\n",
    "trainModel(train_data, validation_data, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBdPXDexTSsX"
   },
   "source": [
    "# 6. Use the trained model to classify input data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Setup a predict image function\n",
    "\n",
    "After completed the training for the customised ResNet50 CNN. We will pass it into the following predictImg() function to predict the output given an unkown input image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1600740763311,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "o_hvMM66goEz"
   },
   "outputs": [],
   "source": [
    "# This function c\n",
    "def predictImg(path,img_width,img_height ,model):\n",
    "    imagep = image.load_img(path, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(imagep)\n",
    "    x = x / 255  # Insures that images are normalized, so it can be compared test on a model that also used normalized training and validation images\n",
    "\n",
    "    x = np.expand_dims(x, axis=0) # flattens the image\n",
    "    prediction = model.predict(x) # Extract the prediction made by the model\n",
    "    print(path)\n",
    "    print(prediction)\n",
    "    findLabel(prediction, 0.2, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1600740765510,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "b3efmUz5gxsj"
   },
   "outputs": [],
   "source": [
    "def findLabel(test, threshold, path):\n",
    "    if (max(test[0]) < threshold):\n",
    "        print(\"no class could be defined for \" + path + \" with threshold 0.85\")\n",
    "    else:\n",
    "        m = max(test[0])\n",
    "        index = [i for i, j in enumerate(list(test[0])) if j == m]\n",
    "        #labeler(index[0], path)\n",
    "        label = list(classes.keys())[index[0]]\n",
    "        print(\"The image '\" + path + \"' belongs to class: \" + label) # Prints the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now we are ready to use the trained model to predict the image.\n",
    "\n",
    "Load our Resnet50 CNN model with the trained weights. The trained weights are stored in the .h5 file.\n",
    "\n",
    "- In the compileModel() function we customised our ResNet50 CNN, we have defined a checkpoint to save the best-trained model. Load this best-trained file(.h5) into the customised ResNet50 CNN by setting the files(.h5) path and name into the model.load_weights() function. What is the best-trained file name?\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "data_dir_path+'custom_w_supervision_try2_best.h5'\n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "\n",
    "Set the unknown images path and name together with the image width and height into the predictImg() function.\n",
    "\n",
    "- Unknow image path and file name\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "    eg.    prediction_data_dir+\"honda1.jpg\"\n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "- What is the width and height to resize the image?\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "The image width and height has to follow the input size of the customised ResNet50. So it should be (197,197).\n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "\n",
    "Try to load different test images from the directory prediction_images to predict the output. You can check the predicted label against the test image file name. The test image file name is the ground truth label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60167,
     "status": "ok",
     "timestamp": 1600742011234,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "LRPFxU8PhC-6",
    "outputId": "f5ad104c-cd36-4906-e187-0d6afcc49a34"
   },
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "model = compileModel()\n",
    "\n",
    "## TODO: Set the best-trained weigth path and file name \n",
    "model.load_weights(#add code)\n",
    "\n",
    "## TODO: Set the unkown image path and file name\n",
    "## TODO: Set the unkown image width and height\n",
    "\n",
    "predictImg(#add code, #add code, #add code , model) # \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkruaBc4pLdY0qKoXWG6qt",
   "name": "Car3_Classification_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf1env)",
   "language": "python",
   "name": "tf1env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
