{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "video-anomaly-exercise-v2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python3.8 (tf2env)",
      "language": "python",
      "name": "tf2env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/aiup/blob/main/day1-pm/video_anomaly_exercise_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeU5auf1gd11"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/mindef-ai/blob/main/day1-pm/video-anomaly-exercise-v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYiEfpsSgd11"
      },
      "source": [
        "<img src=\"https://www.nyp.edu.sg/content/dam/nyp/logo.png\" width=\"238\" height=\"70\"/>\n",
        "\n",
        "Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n",
        "\n",
        "1. The notebook is composed of cells; cells can contain code which you can run, or they can hold text and/or images which are there for you to read.\n",
        "\n",
        "2. You can execute code cells by clicking the ```Run``` icon in the menu, or via the following keyboard shortcuts ```Shift-Enter``` (run and advance) or ```Ctrl-Enter``` (run and stay in the current cell).\n",
        "\n",
        "3. To interrupt cell execution, click the ```Stop``` button on the toolbar or navigate to the ```Kernel``` menu, and select ```Interrupt ```.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gPhj9otgd12"
      },
      "source": [
        "!wget -q https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/codes/dataset_util.py\n",
        "!wget -q https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/codes/utils.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBxiz7qFgd15"
      },
      "source": [
        "# Video Anomaly Detection (Exercise)\n",
        "                                                             \n",
        "Using the previous lab *Video Anomaly Detection* as reference, try to train the model on another dataset and see how it performs.  Complete the codes marked with *TODO*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsSqYgBGgd15"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyhXUePWgd16"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from utils import *\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as ipyImage\n",
        "from dataset_util import prepare_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssSkBYbsgd18"
      },
      "source": [
        "## Dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3mR0zi-gd18"
      },
      "source": [
        "base_dataset_dir = 'video_dataset'\n",
        "datafile_url  = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/UCSD_Anomaly_Dataset.v1p2.zip'\n",
        "download_data(base_dataset_dir, datafile_url, extract=True, force=False)\n",
        "\n",
        "base_dataset_dir = 'video_dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGSTSvsgd1_"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Complete the code below to use the dataset 'UCSDped2'.\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```\n",
        "dataset = 'UCSDped2'\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j2YxcUSgd1_"
      },
      "source": [
        "# TODO:  modify the code\n",
        "dataset =  None\n",
        "\n",
        "# setup all the relative path\n",
        "root_path = os.path.join(base_dataset_dir, dataset)\n",
        "train_dir = os.path.join(root_path, 'Train')\n",
        "test_dir = os.path.join(root_path, 'Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZGta4Y6gd2B"
      },
      "source": [
        "### Visualize the Train dataset\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "Complete the codes below to display sample images from the train sample folder \"Train003\". \n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```\n",
        "train_sample_folder = 'Train003' \n",
        "image_range = (1,9)  # this display image from 1 to 8\n",
        "image_folder = os.path.join(train_dir, train_sample_folder)\n",
        "display_images(image_folder, image_range=image_range, max_per_row=4) \n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTI7Zlxhgd2C"
      },
      "source": [
        "# TODO: complete the code \n",
        "\n",
        "train_sample_folder = None\n",
        "image_range = None  # this display image from 10 to 18\n",
        "image_folder = None\n",
        "display_images(image_folder, image_range=image_range, max_per_row=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mWEN2nWgd2E"
      },
      "source": [
        "We now visualize the image frames as animated gif (like a video)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMNJ4dkvgd2E"
      },
      "source": [
        "gif_filename = train_sample_folder + '.gif' \n",
        "create_gif(image_folder, gif_filename, img_type='tif')\n",
        "\n",
        "with open(gif_filename,'rb') as file:\n",
        "    display(ipyImage(file.read(), format='png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2lMnAsqgd2H"
      },
      "source": [
        "## Visualize the Test dataset\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "- Display test sample images from folder \"Test001\"\n",
        "- Call the create_gif() function to create an animated gif of the video frames in the 'Test001' folder. \n",
        "- Display the gif file.\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```\n",
        "test_sample_folder = 'Test001' \n",
        "image_range = (1,9)  # this display image from 1 to 8\n",
        "image_folder = os.path.join(test_dir, test_sample_folder)\n",
        "display_images(image_folder, image_range=image_range, max_per_row=4)\n",
        "\n",
        "gif_filename = train_sample_folder + '.gif' \n",
        "create_gif(image_folder, gif_filename, img_type='tif')\n",
        "\n",
        "with open(gif_filename,'rb') as file:\n",
        "    display(ipyImage(file.read(), format='png'))\n",
        "    \n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DfOaMq6gd2H"
      },
      "source": [
        "## TODO: Write the coder here, refering to previous lab\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrz1faMGgd2J"
      },
      "source": [
        "### Prepare Training Dataset\n",
        "\n",
        "Here we create a Tensorflow dataset suitable for use in training the Autoencoder network later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akw_T5Yygd2J"
      },
      "source": [
        "IMG_HEIGHT=100\n",
        "IMG_WIDTH=100\n",
        "BATCH_SIZE=16\n",
        "\n",
        "train_fileset = os.path.join(train_dir, '*/*.tif')\n",
        "\n",
        "\n",
        "train_dataset, test_dataset = prepare_dataset(train_fileset,\n",
        "                                img_height=IMG_HEIGHT, \n",
        "                                img_width=IMG_WIDTH, \n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                shuffle=True,\n",
        "                                split=True,\n",
        "                                test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgztHrTMgd2L"
      },
      "source": [
        "### Building the Auto-encoder Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty_fTJdUgd2L"
      },
      "source": [
        "Here we build our autoencoder network.  \n",
        "\n",
        "**Exercise**\n",
        "\n",
        "Change the latent layer's dimension to 1500.\n",
        "\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```\n",
        "encoded = tf.keras.layers.Dense(1500)(x)\n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OCFA2Urgd2M"
      },
      "source": [
        "# The encoder part of the Audo-encoder model\n",
        "inputs = tf.keras.layers.Input(shape=(100,100,1))\n",
        "x = tf.keras.layers.Conv2D(32, kernel_size=5, activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPool2D(pool_size=2)(x)\n",
        "x = tf.keras.layers.Conv2D(32, kernel_size=5, activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D(pool_size=2)(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "## TODO: Modify the code \n",
        "# this is the latent layer\n",
        "encoded = tf.keras.layers.Dense(??)(x)\n",
        "\n",
        "\n",
        "encoder = tf.keras.Model(inputs=[inputs], outputs=[encoded])\n",
        "\n",
        "# The decoder part of the Audo-encoder model\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(1500))\n",
        "x = tf.keras.layers.Dense(22*22*32, activation='relu')(decoder_inputs)\n",
        "x = tf.keras.layers.Reshape(target_shape=(22,22,32))(x)\n",
        "x = tf.keras.layers.UpSampling2D(2, interpolation='nearest')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(32, kernel_size=5, activation='relu')(x)\n",
        "x = tf.keras.layers.UpSampling2D(2, interpolation='nearest')(x)\n",
        "decoded = tf.keras.layers.Conv2DTranspose(1, kernel_size=5, activation='sigmoid')(x)\n",
        "decoder = tf.keras.Model(inputs=[decoder_inputs], outputs=[decoded])\n",
        "\n",
        "encoding = encoder(inputs)\n",
        "decoding = decoder(encoding)\n",
        "conv_ae = tf.keras.Model(inputs=[inputs], outputs=[decoding])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur6WxTRlgd2N"
      },
      "source": [
        "conv_ae.compile(loss=tf.keras.losses.MeanSquaredError(), \n",
        "        optimizer=tf.keras.optimizers.Adam(lr=1e-4, decay=1e-4),\n",
        "        metrics=['mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FybRWuOugd2P"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Train the network for 40 epochs.\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```\n",
        "num_epochs = 40\n",
        "\n",
        "history = conv_ae.fit(train_dataset, \n",
        "                      validation_data=test_dataset,\n",
        "                      epochs=num_epochs)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNRc_1b4gd2Q"
      },
      "source": [
        "## TODO: Complete the code \n",
        "\n",
        "num_epochs = None\n",
        "\n",
        "history = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXkpfX0Ugd2S"
      },
      "source": [
        "plot_training_loss(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BEPIggMgd2U"
      },
      "source": [
        "### Prepare Testing Dataset\n",
        "\n",
        "Now we will create a test dataset that we can use to test the trained auto-encoder. \n",
        "\n",
        "**Exercise**:\n",
        "\n",
        "Add code below to prepare a dataset using samples from test folder \"Test004\".\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "    \n",
        "```\n",
        "BATCH_SIZE=1\n",
        "\n",
        "test_sample_folder = 'Test004'\n",
        "\n",
        "test_fileset = os.path.join(test_dir, test_sample_folder, \"*.tif\")\n",
        "\n",
        "test_dataset = prepare_dataset(test_fileset,\n",
        "                                img_height=IMG_HEIGHT, \n",
        "                                img_width=IMG_WIDTH, \n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                shuffle=False)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBb5OH96gd2U"
      },
      "source": [
        "## TODO: Complete the code \n",
        "\n",
        "BATCH_SIZE=1\n",
        "\n",
        "test_sample_folder = None \n",
        "\n",
        "test_fileset = os.path.join(test_dir, test_sample_folder, \"*.tif\")\n",
        "\n",
        "test_dataset = None \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqVDKUaegd2W"
      },
      "source": [
        "#### Reconstruction loss over different video frames\n",
        "\n",
        "Let us show the reconstruction loss animated over different video frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hvy4ZP1gd2W"
      },
      "source": [
        "create_losses_animation(conv_ae, test_dataset, \"losses.gif\")\n",
        "with open('losses.gif','rb') as file:\n",
        "    display(ipyImage(file.read(), format='png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MN-BIN8gd2Y"
      },
      "source": [
        "#### Identification of anomalous object from the video frames\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "Identify and highlight the area of anomaly in the video frame, using a threshold of 3.5.\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "<br/>\n",
        "\n",
        "```\n",
        "threshold = 4.0\n",
        "identify_anomaly(conv_ae, test_dataset, \"video.gif\", threshold)\n",
        "with open('video.gif','rb') as file:\n",
        "    display(ipyImage(file.read(), format='png'))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8__2KDSEgd2Z"
      },
      "source": [
        "## TODO: Complete the code \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}