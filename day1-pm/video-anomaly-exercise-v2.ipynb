{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/mindef-ai/blob/main/day1-pm/video-anomaly-exercise-v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.nyp.edu.sg/content/dam/nyp/logo.png\" width=\"238\" height=\"70\"/>\n",
    "\n",
    "Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n",
    "\n",
    "1. The notebook is composed of cells; cells can contain code which you can run, or they can hold text and/or images which are there for you to read.\n",
    "\n",
    "2. You can execute code cells by clicking the ```Run``` icon in the menu, or via the following keyboard shortcuts ```Shift-Enter``` (run and advance) or ```Ctrl-Enter``` (run and stay in the current cell).\n",
    "\n",
    "3. To interrupt cell execution, click the ```Stop``` button on the toolbar or navigate to the ```Kernel``` menu, and select ```Interrupt ```.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/codes/dataset_util.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Anomaly Detection (Exercise)\n",
    "                                                             \n",
    "Using the previous lab *Video Anomaly Detection* as reference, try to train the model on another dataset and see how it performs.  Complete the codes marked with *TODO*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from utils import *\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as ipyImage\n",
    "from dataset_util import prepare_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset_dir = 'video_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Complete the code below to use the dataset 'UCSDped2'.\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "    \n",
    "```\n",
    "dataset = 'UCSDped2'\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  modify the code\n",
    "dataset =  None\n",
    "\n",
    "# setup all the relative path\n",
    "root_path = os.path.join(base_dataset_dir, dataset)\n",
    "train_dir = os.path.join(root_path, 'Train')\n",
    "test_dir = os.path.join(root_path, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Train dataset\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Complete the codes below to display sample images from the train sample folder \"Train003\". \n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "    \n",
    "```\n",
    "train_sample_folder = 'Train003' \n",
    "image_range = (1,9)  # this display image from 1 to 8\n",
    "image_folder = os.path.join(train_dir, train_sample_folder)\n",
    "display_images(image_folder, image_range=image_range, max_per_row=4) \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the code \n",
    "\n",
    "train_sample_folder = None\n",
    "image_range = None  # this display image from 10 to 18\n",
    "image_folder = None\n",
    "display_images(image_folder, image_range=image_range, max_per_row=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualize the image frames as animated gif (like a video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_filename = train_sample_folder + '.gif' \n",
    "create_gif(image_folder, gif_filename, img_type='tif')\n",
    "\n",
    "with open(gif_filename,'rb') as file:\n",
    "    display(ipyImage(file.read(), format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Test dataset\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "- Display test sample images from folder \"Test001\"\n",
    "- Call the create_gif() function to create an animated gif of the video frames in the 'Test001' folder. \n",
    "- Display the gif file.\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "    \n",
    "```\n",
    "test_sample_folder = 'Test001' \n",
    "image_range = (1,9)  # this display image from 1 to 8\n",
    "image_folder = os.path.join(test_dir, test_sample_folder)\n",
    "display_images(image_folder, image_range=image_range, max_per_row=4)\n",
    "\n",
    "gif_filename = train_sample_folder + '.gif' \n",
    "create_gif(image_folder, gif_filename, img_type='tif')\n",
    "\n",
    "with open(gif_filename,'rb') as file:\n",
    "    display(ipyImage(file.read(), format='png'))\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Write the coder here, refering to previous lab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Dataset\n",
    "\n",
    "Here we create a Tensorflow dataset suitable for use in training the Autoencoder network later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT=100\n",
    "IMG_WIDTH=100\n",
    "BATCH_SIZE=16\n",
    "\n",
    "train_fileset = os.path.join(train_dir, '*/*.tif')\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = prepare_dataset(train_fileset,\n",
    "                                img_height=IMG_HEIGHT, \n",
    "                                img_width=IMG_WIDTH, \n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                split=True,\n",
    "                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Auto-encoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build our autoencoder network.  \n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Change the latent layer's dimension to 1500.\n",
    "\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "    \n",
    "```\n",
    "encoded = tf.keras.layers.Dense(2000)(x)\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoder part of the Audo-encoder model\n",
    "inputs = tf.keras.layers.Input(shape=(100,100,1))\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=5, activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=5, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "## TODO: Modif the code \n",
    "encoded = tf.keras.layers.Dense(2000)(x)\n",
    "\n",
    "\n",
    "encoder = tf.keras.Model(inputs=[inputs], outputs=[encoded])\n",
    "\n",
    "# The decoder part of the Audo-encoder model\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(2000))\n",
    "x = tf.keras.layers.Dense(22*22*32, activation='relu')(decoder_inputs)\n",
    "x = tf.keras.layers.Reshape(target_shape=(22,22,32))(x)\n",
    "x = tf.keras.layers.UpSampling2D(2, interpolation='nearest')(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(32, kernel_size=5, activation='relu')(x)\n",
    "x = tf.keras.layers.UpSampling2D(2, interpolation='nearest')(x)\n",
    "decoded = tf.keras.layers.Conv2DTranspose(1, kernel_size=5, activation='sigmoid')(x)\n",
    "decoder = tf.keras.Model(inputs=[decoder_inputs], outputs=[decoded])\n",
    "\n",
    "encoding = encoder(inputs)\n",
    "decoding = decoder(encoding)\n",
    "conv_ae = tf.keras.Model(inputs=[inputs], outputs=[decoding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ae.compile(loss=tf.keras.losses.MeanSquaredError(), \n",
    "        optimizer=tf.keras.optimizers.Adam(lr=1e-4, decay=1e-4),\n",
    "        metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Train the network for 40 epochs.\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "    \n",
    "```\n",
    "num_epochs = 40\n",
    "\n",
    "history = conv_ae.fit(train_dataset, \n",
    "                      validation_data=test_dataset,\n",
    "                      epochs=num_epochs)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Complete the code \n",
    "\n",
    "num_epochs = None\n",
    "\n",
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Testing Dataset\n",
    "\n",
    "Now we will create a test dataset that we can use to test the trained auto-encoder. \n",
    "\n",
    "**Exercise**:\n",
    "\n",
    "Add code below to prepare a dataset using samples from test folder \"Test002\".\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "    \n",
    "```\n",
    "BATCH_SIZE=1\n",
    "\n",
    "test_sample_folder = 'Test002'\n",
    "\n",
    "test_fileset = os.path.join(test_dir, test_sample_folder, \"*.tif\")\n",
    "\n",
    "test_dataset = prepare_dataset(test_fileset,\n",
    "                                img_height=IMG_HEIGHT, \n",
    "                                img_width=IMG_WIDTH, \n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=False)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Complete the code \n",
    "\n",
    "BATCH_SIZE=1\n",
    "\n",
    "test_sample_folder = None \n",
    "\n",
    "test_fileset = os.path.join(test_dir, test_sample_folder, \"*.tif\")\n",
    "\n",
    "test_dataset = None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruction loss over different video frames\n",
    "\n",
    "Let us show the reconstruction loss animated over different video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_losses_animation(conv_ae, test_dataset, \"losses.gif\")\n",
    "with open('losses.gif','rb') as file:\n",
    "    display(ipyImage(file.read(), format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of anomalous object from the video frames\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Identify and highlight the area of anomaly in the video frame, using a threshold of 3.5.\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "<br/>\n",
    "\n",
    "```\n",
    "threshold = 4.0\n",
    "identify_anomaly(conv_ae, test_dataset, \"video.gif\", threshold)\n",
    "with open('video.gif','rb') as file:\n",
    "    display(ipyImage(file.read(), format='png'))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Complete the code "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2env",
   "language": "python",
   "name": "tf2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
